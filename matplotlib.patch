Index: /tools/trunk/apps/neelix/bin/neelix
===================================================================
--- /tools/trunk/apps/neelix/bin/neelix	(revision 111775)
+++ /tools/trunk/apps/neelix/bin/neelix	(working copy)
@@ -1,6 +1,7 @@
 #!/usr/bin/env python
 """Neelix is a command line tool for parsing and visually correlating different metrics. For details, please read wiki: http://go/neelix"""
 
+import argparse
 import ConfigParser
 import datetime
 import os
@@ -122,55 +123,58 @@
   graphing_library = 'jfreechart'
   variables_dict = {}
   bin_path = os.path.dirname( __file__ )
+  
+  arg_parser = argparse.ArgumentParser()
 
-  read_neelix_templates()
-
-  cli.add_argument('config', help="file with specifications for each metric and graphs")
-  cli.add_argument('-i', '--input_dir', help="input directory used to construct full path name of the metric infile")
-  cli.add_argument('-o', '--output_dir', help="output directory where the plots and Report.html will be generated")
-  cli.add_argument('-k', '--sshkey_location', help="full path to your ssh key (for fetching files from remote hosts)")
-  cli.add_argument('-p', '--passphrase', help="your ssh key passphrase")
-  cli.add_argument('-host', '--hostname', help="Default remote host for downloading logs from. hostname specified in config takes precedence over this")
-  cli.add_argument('-V', '--variables', action="append", help="User defined variables (in form key=value) for substitution in the config file. Config should have the variable names in format %(key)s")
-  cli.add_argument('-s', '--show_config', help="Print config associated with the provided template name", action="store_true")
+  arg_parser.add_argument('config', help="file with specifications for each metric and graphs")
+  arg_parser.add_argument('-i', '--input_dir', help="input directory used to construct full path name of the metric infile")
+  arg_parser.add_argument('-o', '--output_dir', help="output directory where the plots and Report.html will be generated")
+  arg_parser.add_argument('-k', '--sshkey_location', help="full path to your ssh key (for fetching files from remote hosts)")
+  arg_parser.add_argument('-p', '--passphrase', help="your ssh key passphrase")
+  arg_parser.add_argument('-host', '--hostname', help="Default remote host for downloading logs from. hostname specified in config takes precedence over this")
+  arg_parser.add_argument('-V', '--variables', action="append", help="User defined variables (in form key=value) for substitution in the config file. Config should have the variable names in format %(key)s")
+  arg_parser.add_argument('-s', '--show_config', help="Print config associated with the provided template name", action="store_true")
   #TODO(rmaheshw) : Print a list of all templates supported with descriptions
   #cli.add_argument('-l', '--list_templates', help="List all template configs", action="store_true")
 
-  with cli.run() as c:
+  args = arg_parser.parse_args()
+
+  if args:
+    read_neelix_templates()
     # Print template config
-    if c.args.show_config:
-      tmp_file = linkedin.neelix.metric.download_file(template_urls[c.args.config])
+    if args.show_config:
+      tmp_file = linkedin.neelix.metric.download_file(template_urls[args.config])
       with open(tmp_file, 'r') as FH:
         print "----"
         print FH.read()
       sys.exit("----")
 
     # Download config if its a URL
-    if linkedin.neelix.metric.is_valid_url(c.args.config):
-      optfile = linkedin.neelix.metric.download_file(c.args.config)
-    elif c.args.config.startswith("template:"):
+    if linkedin.neelix.metric.is_valid_url(args.config):
+      optfile = linkedin.neelix.metric.download_file(args.config)
+    elif args.config.startswith("template:"):
       #Its a template
-      if c.args.config in template_urls.keys():
-        print "INFO: Using template " + c.args.config
-        optfile = linkedin.neelix.metric.download_file(template_urls[c.args.config])
+      if args.config in template_urls.keys():
+        print "INFO: Using template " + args.config
+        optfile = linkedin.neelix.metric.download_file(template_urls[args.config])
       else:
-        sys.exit("ERROR: Template " + c.args.config + " not found. Exiting...")
+        sys.exit("ERROR: Template " + args.config + " not found. Exiting...")
       with open(optfile, 'r') as FH:
         print "Config file used looks like this:"
         print "-------------"
         print FH.read()
         print "-------------"
     else:
-      optfile = c.args.config
+      optfile = args.config
 
-    indir_default = c.args.input_dir
-    outdir_default = c.args.output_dir
-    ssh_key_location = c.args.sshkey_location
-    passphrase = c.args.passphrase
-    hostname = c.args.hostname
+    indir_default = args.input_dir
+    outdir_default = args.output_dir
+    ssh_key_location = args.sshkey_location
+    passphrase = args.passphrase
+    hostname = args.hostname
     #user defined variables in form "key=value"
-    if c.args.variables:
-      for var in c.args.variables:
+    if args.variables:
+      for var in args.variables:
         words = var.split('=')
         variables_dict[words[0]] = words[1]
 
@@ -211,10 +215,6 @@
           label = section
           if access == "ssh" and config_obj.has_option(section, 'hostname'):
             hostname = config_obj.get(section, 'hostname')
-          if config_obj.has_option(section, 'outdir'):
-            outdir = config_obj.get(section, 'outdir')
-          else:
-            outdir = None
           if config_obj.has_option(section, 'ts_start'):
             ts_start = config_obj.get(section, 'ts_start')
           else:
@@ -231,7 +231,7 @@
           print "Exception: " , sys.exc_info()[0], "; Something wrong with the format of the config file in section:", section
           sys.exit(0)
         if section == 'SAR-*':
-          sar_metrics = linkedin.neelix.metric.get_all_sar_objects(metrics, infile, access, outdir, label, ts_start, ts_end, None)
+          sar_metrics = linkedin.neelix.metric.get_all_sar_objects(metrics, infile, access, outdir_default, label, ts_start, ts_end, None)
           if config_obj.has_option(section, 'ignore') and config_obj.getint(section, 'ignore') == 1:
             for metric in sar_metrics:
               metric.ignore = True
@@ -240,9 +240,9 @@
           if section.startswith('GC'):
             gc_options_string = config_obj.get(section, 'gc-options')
             gc_options = gc_options_string.split()
-            new_metric = GCMetric(section, infile, access, outdir, label, ts_start, ts_end, gc_options)
+            new_metric = GCMetric(section, infile, access, outdir_default, label, ts_start, ts_end, gc_options)
           elif section.startswith('SAR'):
-            new_metric = SARMetric(section, infile, access, outdir, label, ts_start, ts_end, None)
+            new_metric = SARMetric(section, infile, access, outdir_default, label, ts_start, ts_end, None)
             if config_obj.has_option(section, 'devices'):
               devices_string = config_obj.get(section, 'devices')
               devices = devices_string.split()
@@ -253,7 +253,7 @@
               options = options_string.split()
               new_metric.options = options
           elif section.startswith('INNOTOP'):
-            new_metric = INNOMetric(section, infile, access, outdir, label, ts_start, ts_end, None)
+            new_metric = INNOMetric(section, infile, access, outdir_default, label, ts_start, ts_end, None)
             if config_obj.has_option(section, 'devices'):
               devices_string = config_obj.get(section, 'devices')
               devices = devices_string.split()
@@ -273,14 +273,14 @@
               resolution = config_obj.get(section, 'resolution')
             else:
               resolution = None
-            new_metric = IngraphsMetric(section, infile, access, outdir, label, ts_start, ts_end, ingraphs_type, ingraphs_type_val, consolidate, resolution)
+            new_metric = IngraphsMetric(section, infile, access, outdir_default, label, ts_start, ts_end, ingraphs_type, ingraphs_type_val, consolidate, resolution)
           elif config_obj.has_option(section, 'columns'):
             columns = config_obj.get(section, 'columns')
             if config_obj.has_option(section, 'sep'):
               sep = config_obj.get(section, 'sep')
             else:
               sep = ','
-            new_metric = Metric(section, infile, access, outdir, label, ts_start, ts_end)
+            new_metric = Metric(section, infile, access, outdir_default, label, ts_start, ts_end)
             new_metric.columns = columns.split(',')
             new_metric.sep = sep
             if config_obj.has_option(section, 'titles'):
@@ -294,7 +294,7 @@
             new_metric.titles = dict(zip(new_metric.columns, titles.split(',')))
             new_metric.ylabels = dict(zip(new_metric.columns, ylabels.split(',')))
           else:
-            new_metric = Metric(section, infile, access, outdir, label, ts_start, ts_end)
+            new_metric = Metric(section, infile, access, outdir_default, label, ts_start, ts_end)
           if config_obj.has_option(section, 'ignore') and config_obj.getint(section, 'ignore') == 1:
             new_metric.ignore = True
           if config_obj.has_option(section, 'calc_metrics'):
@@ -317,6 +317,8 @@
     # TODO: Use Jinja templates
     if outdir_default:
       print "Report.html and the plots will be in:", outdir_default
+    else:
+      sys.exit("No output directory defined. Please use option -o, or update the config. Exiting...")
     html_string = []
     metric_string_list = []
     if graph_timezone:
@@ -335,3 +337,4 @@
     linkedin.neelix.metric.generate_html_report(outdir_default, ''.join(html_string))
     if outdir_default:
       print "Report generated at {0}".format( os.path.join(outdir_default, "Report.html") )
+
Index: /tools/trunk/apps/neelix/src/linkedin/neelix/gc_metric.py
===================================================================
--- /tools/trunk/apps/neelix/src/linkedin/neelix/gc_metric.py	(revision 111775)
+++ /tools/trunk/apps/neelix/src/linkedin/neelix/gc_metric.py	(working copy)
@@ -198,52 +198,3 @@
         print "Waiting for thread", t.ident, "to finish...."
         t.join()
     return True
-
-  def graph(self, perfrepo):
-    html_string = []
-    html_string.append('<h1>Metric: {0}</h1>\n'.format(self.metric_type))
-    for outcsv in self.csvfiles:
-      csvfilename = os.path.basename(outcsv)
-      x = '.'.join(csvfilename.split('.')[0:-1])
-      column = '.'.join(x.split('.')[1:])
-      linkedin.neelix.metric.graph_csv(perfrepo, self.outdir, outcsv, x, x)
-      if column in self.metric_description:
-        imgtag = "<h3>{title}</h3><p><b>Description</b>: {description}</p><img src={imgname}.png />\n".format(title=x, description=self.metric_description[column], imgname=x)
-      else:
-        imgtag = "<h3>{0}</h3><img src={1} />\n".format(x, x+'.png')
-      html_string.append(imgtag)
-    return '\n'.join(html_string)
-
-  def graph_old(self, perfrepo):
-    htmlstring = []
-    htmlstring.append("<h1>Metric: {0}</h1>\n".format(self.metric_type))
-    for x in self.rate_types:
-      if not x in self.gc_options:
-        continue
-      xrate = x + '-rate'
-      outcsv = self.get_csv(x)
-      outcsvrate = self.get_csv(xrate)
-      plot_title = self.metric_type + '.' + x
-      linkedin.neelix.metric.graph_csv(perfrepo, self.outdir, outcsv, plot_title, x)
-      plot_title = self.metric_type + '.' + xrate
-      linkedin.neelix.metric.graph_csv(perfrepo, self.outdir, outcsvrate, plot_title, xrate)
-      imgtag = "<h3>{title}</h3><p><b>Description</b>: {description}</p><img src={imgname}.png />\n".format(title=x, description=self.metric_description[x], imgname=x)
-      imgtagrate = "<h3>{0}</h3><img src={1} />\n".format(xrate, xrate + '.png')
-      htmlstring.append(imgtag)
-      htmlstring.append(imgtagrate)
-    for x in self.val_types:
-      if not x in self.gc_options:
-        continue
-      outcsv = self.get_csv(x)
-      plot_title = self.metric_type + '.' + x
-      linkedin.neelix.metric.graph_csv(perfrepo, self.outdir, outcsv, plot_title, x)
-      imgtag = "<h3>{title}</h3><p><b>Description</b>: {description}</p><img src={imgname}.png />\n".format(title=x, description=self.metric_description[x], imgname=x)
-      htmlstring.append(imgtag)
-    # APPSTOP
-    x = 'appstop'
-    outcsv = self.get_csv(x)
-    plot_title = self.metric_type + '.' + x
-    linkedin.neelix.metric.graph_csv(perfrepo, self.outdir, outcsv, plot_title, x)
-    imgtag = "<h3>{0}</h3><img src={1} />\n".format(x, x + '.png')
-    htmlstring.append(imgtag)
-    return '\n'.join(htmlstring)
Index: /tools/trunk/apps/neelix/src/linkedin/neelix/ingraphs_metric.py
===================================================================
--- /tools/trunk/apps/neelix/src/linkedin/neelix/ingraphs_metric.py	(revision 111775)
+++ /tools/trunk/apps/neelix/src/linkedin/neelix/ingraphs_metric.py	(working copy)
@@ -49,6 +49,9 @@
     with open(out_csv, 'w') as FH:
       self.csvfiles.append(out_csv)
       for ts in sorted(data):
+        if data[ts] is None:
+          print "InGraphs: Skipping None data"
+          continue
         #TODO(rmaheshw): Decide if you want to use reconcile_timezones method here or not
         dt = datetime.datetime.fromtimestamp(float(ts))
         #Initializing ts_string with local timezone conversion
@@ -62,10 +65,7 @@
           ts_string = dt.strftime("%Y-%m-%d %H:%M:%S.%f")
         FH.write(ts_string)
         FH.write(',')
-        if data[ts] == "None":
-          FH.write()
-        else:
-          FH.write(str(data[ts]))
+        FH.write(str(data[ts]))
         FH.write('\n')
     return True
 
Index: /tools/trunk/apps/neelix/src/linkedin/neelix/metric.py
===================================================================
--- /tools/trunk/apps/neelix/src/linkedin/neelix/metric.py	(revision 111775)
+++ /tools/trunk/apps/neelix/src/linkedin/neelix/metric.py	(working copy)
@@ -1,5 +1,7 @@
 import calendar
 import datetime
+from matplotlib import pyplot as plt, dates as mdates
+import numpy as np
 import os
 import pytz
 from pytz import timezone
@@ -88,7 +90,7 @@
   except ValueError:
     return False
 
-def get_all_sar_objects(metrics, indir, access, outdir, label, ts_start, ts_end, options):
+def get_all_sar_objects(metrics, indir, access, output_directory, label, ts_start, ts_end, options):
   metrics = []
   sar_types = ('device', 'cpuusage', 'cpuhz', 'memory', 'memutil', 'paging')
   for sar_metric_type in sar_types:
@@ -96,7 +98,7 @@
     infile = os.path.join(indir, 'sar.' + sar_metric_type + '.out')
     if os.path.exists(infile):
       obj_type = 'SAR-' + sar_metric_type
-      metric = SARMetric(obj_type, infile, access, outdir, label, ts_start, ts_end, options)
+      metric = SARMetric(obj_type, infile, access, output_directory, label, ts_start, ts_end, options)
       metrics.append(metric)
   return metrics
 
@@ -108,9 +110,9 @@
     string = string.replace('%', '-percent-')
   return string
 
-def get_default_csv(outdir, val):
+def get_default_csv(output_directory, val):
   val = sanitize_string(val)
-  return os.path.join(outdir, val + '.csv')
+  return os.path.join(output_directory, val + '.csv')
 
 def convert_to_24hr_format(ts):
   words = ts.split()
@@ -128,8 +130,8 @@
     ts = ":".join(tmp)
   return ts
 
-def get_merged_csvname(outdir, vals):
-  return os.path.join(outdir, '-'.join(vals) + '.csv')
+def get_merged_csvname(output_directory, vals):
+  return os.path.join(output_directory, '-'.join(vals) + '.csv')
 
 def get_merged_charttitle(vals):
   return " vs ".join(vals)
@@ -140,38 +142,71 @@
 def get_merged_pngname(vals):
   return '-'.join(vals) + '.png'
 
-def graph_csv(perfrepo, outdir, csvfile, plot_title, outfilename, ylabel=None, precision=None):
-  ''' Single metric graphing function '''
-  if os.path.getsize(csvfile) == 0:
+def convert_to_mdate(s):
+  try:
+    d = mdates.strpdate2num('%Y-%m-%d %H:%M:%S.%f')(s)
+  except:
+    d = mdates.strpdate2num('%Y-%m-%d %H:%M:%S')(s)
+  return d
+
+#TODO(rmaheshw): use kwargs in all graph_csv methods
+def graph_csv_jfreechart(output_directory, csv_file, plot_title, output_filename, y_label=None, precision=None):
+  """ Single metric graphing function """
+  if not os.path.getsize(csv_file):
     return False
-  if not ylabel:
-    ylabel = plot_title
+  y_label = y_label or plot_title
 
   jar_dir = linkedin.neelix.java.generate_jar_dir()
   java_repository = JavaEnvironment(jar_dir_classpath(jar_dir))
   if precision and precision == 'ms':
     java_repository.call('com.linkedin.util.PlotGC',
-      "-charts", plot_title, "-cols", ylabel,"-in", csvfile, "-out", outdir,
-      "-plotonsamegraph", "true", "-granularity", "ms", "-pngnames", outfilename)
+      "-charts", plot_title, "-cols", y_label,"-in", csv_file, "-out", output_directory,
+      "-plotonsamegraph", "true", "-granularity", "ms", "-pngnames", output_filename)
   else:
     java_repository.call('com.linkedin.util.PlotGC',
-      "-charts", plot_title, "-cols", ylabel,"-in", csvfile, "-out", outdir,
-      "-plotonsamegraph", "true", "-pngnames", outfilename)
+      "-charts", plot_title, "-cols", y_label,"-in", csv_file, "-out", output_directory,
+      "-plotonsamegraph", "true", "-pngnames", output_filename)
   return True
 
-def graph_csv_dygraphs(outdir, csvfile, plot_title, outfilename, ylabel=None, precision=None, graph_height="600", graph_width="1500"):
-  ''' Single metric graphing function '''
-  if os.path.getsize(csvfile) == 0:
+def graph_csv_matplotlib(output_directory, csv_file, plot_title, output_filename, y_label=None, precision=None, graph_height="600", graph_width="1500", graph_type="line", graph_color="black"):
+  """ Single metric graphing function using matplotlib"""
+  if not os.path.getsize(csv_file):
     return False
-  if not ylabel:
-    ylabel = plot_title
+  y_label = y_label or plot_title
+  days, impressions = np.loadtxt(csv_file, unpack=True, delimiter=",", converters={ 0: convert_to_mdate})
+  fig = plt.figure()
+  fig.set_size_inches(float(graph_width) / 80, float(graph_height) / 80)
+  if graph_type == "line":
+    line_style = "-"
+    marker = None
+  else:
+    marker = "."
+    line_style = None
+
+  plt.plot_date(x=days, y=impressions, linestyle=line_style, marker=marker, color=graph_color)
+  plt.title(plot_title)
+  plt.ylabel(y_label)
+  plt.grid(True)
+  # Get current axis and its xtick labels
+  labels = plt.gca().get_xticklabels()
+  for label in labels:
+    label.set_rotation(30)
+  plot_file_name = os.path.join(output_directory, output_filename + ".png")
+  fig.savefig(plot_file_name)
+  return True
+
+def graph_csv_dygraphs(output_directory, csv_file, plot_title, output_filename, y_label=None, precision=None, graph_height="600", graph_width="1500"):
+  """ Single metric graphing function """
+  if not os.path.getsize(csv_file):
+    return "" 
+  y_label = y_label or plot_title
   thread_id = threading.current_thread().ident;
   div_id = str(thread_id) + str(time.time())
   div_string = "<div id=\"%s\" style=\"width:%spx; height:%spx;\"></div>" % (div_id, graph_width, graph_height)
   script_string = """<script type=\"text/javascript\">
         g2 = new Dygraph(
           document.getElementById(\"""" + div_id + """"),
-            \"""" + os.path.basename(csvfile) +  """",
+            \"""" + os.path.basename(csv_file) +  """",
             {
                      axes: {
                         x: {
@@ -181,9 +216,9 @@
                         }
                      },
                         xlabel: "Time",
-                        ylabel: \"""" + ylabel + """",
+                        ylabel: \"""" + y_label + """",
                         title: \"""" + plot_title + """",
-                        labels: ["Time",\"""" + ylabel + """"]
+                        labels: ["Time",\"""" + y_label + """"]
             }          // options
         );
         </script>"""
@@ -192,32 +227,31 @@
   jar_dir = linkedin.neelix.java.generate_jar_dir()
   java_repository = JavaEnvironment(jar_dir_classpath(jar_dir))
   java_repository.call('com.linkedin.util.PlotGC',
-      "-charts", plot_title, "-cols", ylabel,"-in", csvfile, "-out", outdir,
-      "-plotonsamegraph", "true", "-pngnames", outfilename)
-
+      '-charts', plot_title, '-cols', y_label,'-in', csv_file, '-out', output_directory,
+      '-plotonsamegraph', 'true', '-pngnames', output_filename)
   return div_string + script_string
 
-def graph_csv_n(perfrepo, outdir, csvfile, plot_title, outfilename, columns):
-  ''' graph a csv file with n columns '''
+def graph_csv_n(perfrepo, output_directory, csv_file, plot_title, output_filename, columns):
+  """ graph a csv file with n columns """
   jar_dir = linkedin.neelix.java.generate_jar_dir()
   java_repository = JavaEnvironment(jar_dir_classpath(jar_dir))
 
   java_repository.call('com.linkedin.util.PlotGC',
-      "-charts", plot_title, "-cols", ','.join(columns),"-in", csvfile, "-out", outdir,
-      "-plotonsamegraph", "true", "-pngnames", outfilename)
+      '-charts', plot_title, '-cols', ','.join(columns),'-in', csv_file, '-out', output_directory,
+      '-plotonsamegraph', 'true', '-pngnames', output_filename)
 
-def generate_html_report(outdir, html_string):
-  htmlfilename = os.path.join(outdir, 'Report.html')
+def generate_html_report(output_directory, html_string):
+  htmlfilename = os.path.join(output_directory, 'Report.html')
   with open(htmlfilename, 'w') as htmlf:
-    header = "<html><head>"
-    dygraphs_include = """<script type="text/javascript"
-      src="http://dygraphs.com/dygraph-combined.js"></script>
+    header = '<html><head>'
+    dygraphs_include = '''<script type='text/javascript'
+      src='http://dygraphs.com/dygraph-combined.js'></script>
       </head>
-      <body>"""
+      <body>'''
     htmlf.write(header)
     htmlf.write(dygraphs_include)
     htmlf.write(html_string)
-    footer = "</body></html>"
+    footer = '</body></html>'
     htmlf.write(footer)
 
 def tscsv_nway_file_merge(outfile, filelist, filler):
@@ -230,7 +264,7 @@
       try:
         filehandlers[i] = open(filelist[i], 'r')
       except IOError:
-        print "Cannot open:", filelist[i]
+        print 'Cannot open:', filelist[i]
         return
       currlines[i] = filehandlers[i].readline().strip()
     while True:
@@ -260,10 +294,10 @@
             outwords.append(filler)
       outf.write( ','.join(outwords) + '\n' )
 
-def nway_plotting(crossplots, perfrepo, metrics, outdir, filler):
+def nway_plotting(crossplots, perfrepo, metrics, output_directory, filler):
   listlen = len(crossplots)
   if listlen == 0:
-    return ""
+    return ''
   html_string = []
   linkstring = []
   linkstring.append("<h1><a name=\"Correlated-Plots\"></a>Correlated Plots</h1>\n")
@@ -275,41 +309,37 @@
     vals = plot.split(',')
     i += 1
     if not 'all' in vals:
-      csvfiles = []
+      csv_files = []
       for val in vals:
-        csvfile = get_default_csv(outdir, val)
-        csvfiles.append(csvfile)
+        csv_file = get_default_csv(output_directory, val)
+        csv_files.append(csv_file)
       for j in range(len(vals)):
         vals[j] = sanitize_string(vals[j])
-      mergedfilename = get_merged_csvname(outdir, vals)
+      mergedfilename = get_merged_csvname(output_directory, vals)
       plot_title = get_merged_charttitle(vals)
       pngname = get_merged_plot_link_name(vals)
       merged_plotfile = get_merged_pngname(vals)
 
-      tscsv_nway_file_merge(mergedfilename, csvfiles, filler)
-      graph_csv_n(perfrepo, outdir, mergedfilename, plot_title, pngname, vals)
+      tscsv_nway_file_merge(mergedfilename, csv_files, filler)
+      graph_csv_n(perfrepo, output_directory, mergedfilename, plot_title, pngname, vals)
 
-      #imgtag = "<h3><a name=\"%s\"></a>%s</h3><img src=%s />" % (pngname, plot_title, merged_plotfile)
-      #linktag = "<li><a href=\"#%s\">%s</a></li>" % (pngname, plot_title)
-      imgtag = "<h3><a name=\"{0}\"></a>{1}</h3><img src={2} />".format(pngname, plot_title, merged_plotfile)
+      img_tag = "<h3><a name=\"{0}\"></a>{1}</h3><img src={2} />".format(pngname, plot_title, merged_plotfile)
       linktag = "<li><a href=\"#{0}\">{1}</a></li>".format(pngname, plot_title)
-      html_string.append(imgtag)
+      html_string.append(img_tag)
       linkstring.append(linktag)
     else:
       vals.remove('all')
       for metric in metrics:
-        for csv in metric.csvfiles:
+        for csv in metric.csv_files:
           csv_filename = csv.split('/')[-1]
-          x = '.'.join(csv_filename.split('.')[0:-1])
-          if x in vals:
+          metric_name = '.'.join(csv_filename.split('.')[0:-1])
+          if metric_name in vals:
             continue
           new_val = []
           new_val.extend(vals)
-          new_val.append(x)
+          new_val.append(metric_name)
           new_val_str = ','.join(new_val)
           crossplots.append(new_val_str)
-          #print "crossplots"
-          #print crossplots
           listlen += 1
   linkstring.append("</ul></div>")
   linkstring.extend(html_string)
@@ -325,13 +355,14 @@
   ignore = False
   timezone = "PDT"
   # Parsed csv files
-  csvfiles = []
+  csv_files = []
+  metric_description = []
 
-  def __init__ (self, metric_type, infile, inaccess, outdir, label, ts_start, ts_end):
+  def __init__ (self, metric_type, infile, inaccess, output_directory, label, ts_start, ts_end):
     self.metric_type = metric_type
     self.infile = infile
     self.inaccess = inaccess
-    self.outdir = outdir
+    self.outdir = output_directory
     self.label = label
     self.ts_start = ts_start
     self.ts_end = ts_end
@@ -401,7 +432,7 @@
             data[out_csv].append( ts + ',' + words[i+1] )
     # Post processing, putting data in csv files
     for csv in data.keys():
-      self.csvfiles.append(csv)
+      self.csv_files.append(csv)
       with open(csv, 'w') as fh:
         fh.write('\n'.join(data[csv]))
     return True
@@ -423,7 +454,7 @@
         continue
       old_metric_csv = self.get_csv(old_metric)
       new_metric_csv = self.get_csv(newmetric)
-      self.csvfiles.append(new_metric_csv)
+      self.csv_files.append(new_metric_csv)
       oldval = None
       with open(old_metric_csv, 'r') as FH:
         with open(new_metric_csv, 'w') as NEW_FH:
@@ -446,17 +477,28 @@
             NEW_FH.write(str(new_metric_val))
             NEW_FH.write('\n')
 
-  def graph(self, perfrepo, graphing_library = 'jfreechart'):
+  def graph(self, perfrepo, graphing_library = 'matplotlib'):
     html_string = []
     html_string.append('<h1>Metric: {0}</h1>\n'.format(self.metric_type))
-    for out_csv in self.csvfiles:
+    graphed = False
+    for out_csv in self.csv_files:
       csv_filename = os.path.basename(out_csv)
       # The last element is .csv, don't need that in the name of the chart
-      x = '.'.join(csv_filename.split('.')[0:-1])
+      graph_title = '.'.join(csv_filename.split('.')[0:-1])
+      column = '.'.join(graph_title.split('.')[1:])
       if graphing_library in ('dygraphs', 'javascript', 'js'):
-        html_string.append(graph_csv_dygraphs(self.outdir, out_csv, x, x))
+        html_string.append(graph_csv_dygraphs(self.outdir, out_csv, graph_title, graph_title))
       else:
-        graph_csv(perfrepo, self.outdir, out_csv, x, x)
-        imgtag = "<h3>{0}</h3><img src={1} />\n".format(x, x+'.png')
-        html_string.append(imgtag)
+        if graphing_library in ('matplotlib'):
+          graphed = graph_csv_matplotlib(self.outdir, out_csv, graph_title, graph_title)
+        else:
+          graphed = graph_csv_jfreechart(self.outdir, out_csv, graph_title, graph_title)
+        if graphed:
+          if column in self.metric_description:
+            img_tag = "<h3>{title}</h3><p><b>Description</b>: {description}</p><img src={image_name}.png />\n".format(title=graph_title, description=self.metric_description[column], image_name=graph_title)
+          else:
+            img_tag = "<h3>{title}</h3><img src={image_name} />\n".format(title=graph_title, image_name=graph_title + '.png')
+        else:
+          img_tag = "<h3>No data for this metric</h3>"
+        html_string.append(img_tag)
     return '\n'.join(html_string)
